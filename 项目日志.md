# 项目日志

## 2022年11月27日

**Kinect部分**

* openpose连接网络摄像头

  1. 查看是否有摄像头usb驱动：`ls /dev/v*` 如果结果含有 `/dev/video0` 则有。

  2. 查看usb信息： `lsusb` 查看哪一个是连接的摄像头。

     经查，kinect摄像头ID为 `045e:097a~e` 

* 使用openpose模型

  * https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc
  * cmd方法：在 `~/3d_motion/openpose/openpose` 目录下输入命令，注意退出conda： `conda deactivate`
  * 得到姿态点（2d）：保存为 `.json` 文件，注意专门准备一个文件夹存放，因为它会保存每一帧的姿态点。

* linux系统卡死

  `ctrl+alt+T` 打开一个新的命令行，输入 `sudo pkill Xorg` 注销桌面，重新登陆用户即可。**不要直接重启！！** 

## 2023年2月17日

**Kinect部分**

* 开启kinect时需要管理员权限！ `sudo k4aviewer`

  否则会报错 `Is the device being used by another application?`

* Kinect 使用的主要文件的安装位置

  * `k4aviewer  /usr/bin/k4aviewer `
  * `k4a.h /usr/include/k4a/k4a.h`

## 2023年2月18日

### **Kinect SDK安装**

* 进展：安装了附带 example 的 Kinect SDK源码； 使用 cmake 成功编译示例程序。
* 安装 Kinect SDK 源码：http://t.csdn.cn/rRdsC
  * 1.7.2安装ninja一步给的域名错误！应为`https://github.com/ninja-build/ninja-git`
  * cmake前需要手动下载一项（文档中有），下载好之后再cmake。报错没关系，只要检查 `/extern/libusb` 等文件夹中已经下载好文件即可进行后续步骤。
* 编译 Kinect 应用程序
  * 在 `/examples/CMakelists.txt` 中添加 `find_package(k4a REQUIRED)` 等语句！（非常重要，否则cmake时会报错：找不到 k4a::k4a）
  * 关于 cmake 的更多内容还需学习。
* 其他
  * 遇到报错时先试试 **sudo** ！！
  * 运行程序时注意，当前 Kinect 的编号是 0， 传参时不要出错。
  * 下载时卡住，可能是 github 崩了

---

### **Openpose 编译错误**

- 今天重新编译Openpose代码，出现如下问题：

  ```
  nvcc fatal : Unsupported gpu architecture 'compute_80' 
  ```

  查阅资料得知，是当前电脑显卡算力不支持8.0。

  经过查找[Nvidia官网](https://developer.nvidia.com/cuda-gpus)，显卡Quadro P4000的算力为6.1。

  解决方法参考[网站](https://blog.csdn.net/haiy2011/article/details/128968934)，在 `openpose/cmake/Cuda.cmake` 文件夹，将不支持的算力注释掉即可。


- openpose源代码理解

  - `std::make_shared <FlirReader> (cameraParameterPath, cameraResolution, undistortImage, std::stoi(producerString));`

    上述代码表示生成一个`shared_ptr` , 该指针指向一个数据类型为 `FlirReader` 的数据，括号内为对应数据的构造函数所需参数。


  - ```c++
    // If custom user Worker in same thread
    else if (!userInputWs.empty())
    workersAux = mergeVectors(userInputWs, workersAux);
    // If OpenPose producer (same thread)
    else if (datumProducerW != nullptr)
    workersAux = mergeVectors({datumProducerW}, workersAux);
    ```

​			   这行代码表明 `userInputWs` 和 `{datumProducerW}` 为同一个类型。

## 2023年2月19日

### **Openpose部分——3d解释器编译**

今天在尝试加入 `WITH_3D_RENDERER` 和 `WITH_CERES` 的标志后重新编译openpose源代码，遇到了如下的BUG信息：

- BUG:  `error: 'integer_sequence' is not a member of  'std'`

  经过查询信息，发现是当前安装的 ceres-solver 版本不匹配所导致的。当使用当前 [官网](http://ceres-solver.org/installation.html#linux) 下载的版本（ `ceres-solver-2.1.0` ）将出现上述问题。

  解决方法是安装旧版本的ceres-solver, 大致过程为卸载新版的ceres-solver，之后安装1.14.0版本即可。具体操作参考[网址](https://blog.csdn.net/qq_41586768/article/details/107541917)，其中 **编译ceres_curve_fiiting** 步骤不需要操作

- WARNING:  在使用cmake gui进行configure操作时，出现有关`OpenGL_GL_PREFERENCE` 的warning信息。

  `OpenGL_GL_PREFERENCE` 原始被设置为 "LEGACY", 但是Openpose推荐设置为 “GLVND”。

  我们采用的解决方法比较暴力，在 `usr/local/share/cmake-3.25/Modules` 目录下找到，`FindOpenGL.cmake` 文件，将其中如下代码注释掉：

  ```cmake
  set(OpenGL_GL_PREFERENCE "LEGACY")
  if ("x${_OpenGL_GL_POLICY}x" STREQUAL "xx")
  	set(_OpenGL_GL_POLICY_WARN 1)
  endif()
  ```

  并修改为：

  ```cmake
  set(OpenGL_GL_PREFERENCE "GLVND")
  ```

  这种做法不推荐，在warning信息中提示使用command_policy()操作，但是没有找到正确的使用方法。

- **BUG:** 

  ```xml
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutSolidSphere'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutDisplayFunc'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutGetModifiers'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutLeaveMainLoop'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutInitWindowPosition'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutSwapBuffers'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutInitWindowSize'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutSolidCone'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutMouseFunc'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutMainLoopEvent'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutPostRedisplay'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutCreateWindow'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutInit'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutKeyboardFunc'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutMotionFunc'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutInitDisplayMode'
  collect2: error: ld returned 1 exit status
  examples/deprecated/CMakeFiles/tutorial_api_thread_2_user_input_processing_output_and_datum.bin.dir/build.make:176: recipe for target 'examples/deprecated/tutorial_api_thread_2_user_input_processing_output_and_datum.bin' failed
  make[2]: *** [examples/deprecated/tutorial_api_thread_2_user_input_processing_output_and_datum.bin] Error 1
  CMakeFiles/Makefile2:1176: recipe for target 'examples/deprecated/CMakeFiles/tutorial_api_thread_2_user_input_processing_output_and_datum.bin.dir/all' failed
  make[1]: *** [examples/deprecated/CMakeFiles/tutorial_api_thread_2_user_input_processing_output_and_datum.bin.dir/all] Error 2
  make[1]: *** Waiting for unfinished jobs....
  
  ```

  该错误产生的原因为-lGLU -lGL -lglut没有与编译器链接。发现错误原因是通过参考该[网站 ](https://community.khronos.org/t/error-undefined-reference/17579)，以及和 ChatGPT 的询问中理解的。

  但是上述网站并没有给出如何在Openpose源码的编译下，实现链接操作。通过参考[gitHub上Openpose的Issues](https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/440)，找到解决问题的关键是修改Openpose目录下的 `CMakeLists.txt` 文件，将如下代码从：

  ```cmake
  if (WITH_3D_RENDERER)
    set(OpenPose_3rdparty_libraries ${OpenPose_3rdparty_libraries} ${GLUT_LIBRARY} ${OPENGL_LIBRARIES})
  endif (WITH_3D_RENDERER) 
  ```

  修改为：

  ```cmake
  if (WITH_3D_RENDERER)
    set(OpenPose_3rdparty_libraries ${OpenPose_3rdparty_libraries} ${GLUT_LIBRARY} ${OPENGL_LIBRARIES} -lGLU -lGL -lglut)
  endif (WITH_3D_RENDERER) 
  ```

  即可成功链接。

- 在今天的debug环节中，ChatGPT虽然没有给出任何一个可以解决问题的方案，但是通过合理营造语境描述错误信息，**可以帮助理解问题产生的原因，以及相关陌生代码文件或是陌生命令行指令**，从而间接的帮助问题的解决。

---

在linux上安装了QQ，用于实时与另一台设备进行信息通讯

---

### **相机标定知识篇**

* 相机将三维世界中的物体记录在二维的图片中，因此，可以认为相机是一个函数，输入是三维场景，输出为二维图像。**相机标定**就是找到一个合适的数学模型来描述这个函数。这样，我们就可以利用它的反函数，由二维图像重建三维场景。

  ![](.\pictures\pictures for kw\相机标定原理.png)

* **坐标系**

  为了得到数学模型，我们需要使用坐标系：

  * **世界坐标系(world coordinate system)** 现实世界的绝对坐标系，以现实三维空间中某一点为原点建系，描述相机和物体的坐标。 用 `(Xw, Yw, Zw)` 表示坐标值。

  * **相机(camera)坐标系** 以相机的光心为原点的坐标系，描述物体相对于相机光心的位置。用 `(Xc, Yc, Zc)` 表示坐标值，相机的光轴为Z轴，X、Y轴分别平行于图像坐标系的X、Y轴。

    **光心** 大多数相机都是利用小孔成像原理。将相机透镜组抽象为一个小孔模型，小孔中心即为光心。

  * **图像(image)坐标系** 以CCD图像（即相机拍摄到的原始图像）中心为坐标原点，描述图片中像素的位置。用 `(x, y)` 表示坐标值，单位为现实物理长度（如毫米）。

  * **像素(pixel)坐标系** 以数字图像的左上角为坐标原点，描述图片中像素的位置。用 `(u, v)` 表示坐标值，单位为个（像素个数）

    **原始图像 -> 数字图像** 相机拍摄的图片包含若干像素，每个像素点有它的颜色。数字图像用数字表示每个点的颜色。

![](.\pictures\pictures for kw\图像坐标系与像素坐标系.png)

* 内参矩阵

  采用齐次坐标，使用矩阵将上式表示为

  ![](.\LearningNotes\pictures\pictures for kw\图像坐标系到像素坐标系.jpg)

  其中 `(u0, v0)` 是图像坐标系原点在像素坐标系中的坐标（由上述定义可知，坐标为图像分辨率的一半），`dx` 和 `dy` 分别为每个像素在图像平面对应方向上的物理尺寸。

  相机坐标系到图像坐标系的转换，如下图：

  ![](.\pictures\pictures for kw\相机坐标系到图像坐标系.jpg)

  上式中XYZ为物体在相机坐标系中的位置，为具体数值。

  结合上述两个变换，我们得到**内参矩阵**
  $$
  M=
  \begin{bmatrix}
  \frac{1}{dx} & 0 & u0 \\
  0 & \frac{1}{dy} & v0 \\
  0 & 0 & 1
  \end{bmatrix}
  \begin{bmatrix}
  f & 0 & 0 \\
  0 & f & 0 \\
  0 & 0 & 1
  \end{bmatrix}
  =
  \begin{bmatrix}
  f_x & 0 & u0 \\
  0 & f_y & v0 \\
  0 & 0 & 1
  \end{bmatrix}
  $$
  其中 fx，fy 表示在相机拍摄的图像中，长度等于焦距 f 的一段中包含的像素点个数。称 M 为内参矩阵，是因为矩阵 M 的各个元素值只与相机内部参数有关。**利用内参矩阵，可以方便地从相机坐标系变换到像素坐标系。**

* **外参矩阵**

  要得到世界坐标系到像素坐标系的变换，则需要知道这两个三维坐标系之间的相对旋转矩阵 **R** (3×3)和相对位移矩阵 **T** (3×1)。用矩阵表示变换：

  ![](.\pictures\pictures for kw\外参矩阵.png)

  综上，即可实现完整的变换。上式中，Z~c~ 为物体到光心的距离，即**深度距离**！

* **畸变模型**

  实际的相机并不是完美的小孔成像模型，因此实际成像会有畸变。畸变包括**径向畸变**和**切向畸变**等，是由于焦平面上不同区域对图像的放大率不同形成的画面扭曲变形的现象。

  使用3个畸变参数矫正径向畸变（原理：以光心为圆心，r=0处泰勒展开取前几项）
  $$
  x_{rcorr}=x_p(1+k_1r^2+k_2r^4+k_3r^6) \\
  y_{rcorr}=y_p(1+k_1r^2+k_2r^4+k_3r^6)
  $$
  使用2个畸变参数描述切向畸变
  $$
  x_{tcorr}=x_p+[2p_1x_py_p+p_2(r^2+2x_p^2)] \\
  y_{tcorr}=y_p+[p_1(r^2+2y_p^2)+2p_2x_py_p]
  $$

## 2023年2月21日

### **安装 ROS for Azure Kinect DK**

* 官网教程 https://github.com/microsoft/Azure_Kinect_ROS_Driver

* 当前 Kinect 版本为1.4.1

* 安装 ROS 官网教程 https://wiki.ros.org/installation/Ubuntu

  跟着官网教程会出错 `Command: 'catkin_make' not found`

* 使用以下命令（来自 https://blog.csdn.net/haiyinshushe/article/details/84256137）

  1. `sudo sh -c '. /etc/lsb-release && echo "deb http://mirrors.ustc.edu.cn/ros/ubuntu/ $DISTRIB_CODENAME main" > /etc/apt/sources.list.d/ros-latest.list'`

  2. `sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key 421C365BD9FF1F717815A3895523BAEEB01FA116`

     如果不行，中间的hkp密钥部分可以使用 `hkp://ha.pool.sks-keyservers.net:80  或  hkp://pgp.mit.edu:80`

  3. `sudo apt-get update`

  4. `sudo apt-get install ros-melodic-desktop-full`

  5. 初始化rosdep

     `sudo apt-get install python-rosdep`

     `sudo rosdep init`

     `rosdep update`

  6. 添加ros环境变量

     `echo "source /opt/ros/melodic/setup.bash" >> ~/.bashrc
     source ~/.bashrc`

  7. 安装rosinstall

  至此ROS安装完成。

* 安装 Kinect ROS http://t.csdn.cn/rRdsC

  1. 下载ROS驱动

     `mkdir -p ~/KinectDK_ws/src
     cd ~/KinectDK_ws/src
     catkin_init_workspace
     git clone https://github.com/microsoft/Azure_Kinect_ROS_Driver.git`

  2. 下载 libk4a 和 libk4a-dev 文件（版本1.4.1）https://packages.microsoft.com/ubuntu/18.04/prod/pool/main/libk/libk4a1.2/

  3. 创建文件夹存放上述文件

     `cd ~/KinectDK_ws/src
     mkdir -p ext/sdk`

     在sdk文件夹下再创建3个文件夹：

     1. bin文件夹: 把编译 SDK 时 build 文件夹里面的那个 bin 文件夹直接拷贝过来
     2. include文件夹：SDK 源码里的include文件夹与从 deb 文件里提取出的 include 文件夹合并，拷贝过来
     3. lib文件夹：从deb文件里提取出的两个lib文件夹合并，拷贝过来 **注意：这里是两个lib文件**

     **注：打开deb文件的方法** 不要解压，右键选择 `Open with other application` 再选择 `Archive Manager`

  4. 编译及启用

     `cd ~/KinectDK_ws
     catkin_make
     catkin_make install
     source ./devel/setup.bash
     roslaunch azure_kinect_ros_driver driver.launch `

     `rviz`

     catlin_make install 一步会报错，原因不明。不会影响后续操作（也许）

     **roslunch 一步若报错，将kinect重启即可**

  * 错误汇总

    `rviz` 需要在另一个命令行中开启（roslaunch需处于运行状态），同时退出conda环境！

## 2023年2月25日

### 使用 Ros 标定 Kinect 相机

* 参考文章 http://t.csdn.cn/zQKpg

* 详细步骤

  * 开启 ros 可视化窗口

    `cd ~/KinectDK_ws
    catkin_make
    catkin_make install
    source ./devel/setup.bash
    roslaunch azure_kinect_ros_driver driver.launch `

    然后开启另一个命令行

    `rviz`

  * 显示 Kinect 相机图像

    `Add -> Image -> Image Topic -> /rgb/image_raw`

    （上面是显示RGB图像的例子，也可以显示深度图像等）

  * 安装 ros 标定包

    `sudo apt-get install ros-melodic-camera-calibration`

  * 相机标定

    `rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.024 image:=/rgb/image_raw`


* 用 openpose 标定相机

  * 查看 webcam `v4l2-ctl --list-devices`

  * 官方教程 [openpose/calibration_module.md at master · CMU-Perceptual-Computing-Lab/openpose · GitHub](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/advanced/calibration_module.md#introduction)

    **注意：标定时需要拍摄足够的照片（至少约150张），否则无法产生标定结果，会报错**  `image could not be opened!`

  * 标定：在 `/openpose/openpose` 下

    `../openpose/build/examples/calibration/calibration.bin --mode 1 --grid_square_size_mm 20.0 --grid_number_inner_corners "8x6" --camera_serial_number 18079958 --calibration_image_dir ../intrinsic/ --camera_parameter_folder models/cameraParameters/`

### 修改Openpose源码，加入KinectCamera标志

尝试修改Openpose源码，进行再编译，实现过程中出现如下错误：

- 编译错误：`Syntax error: "(" unexpected` 

  将源码文件夹名从 `Openpose(copy)` 改为  `Openpose-copy` 即可

- 编译错误：

  ```xml
  error: ‘FLAGS_kinect_camera’ was not declared in this scope
               FLAGS_flir_camera, FLAGS_flir_camera_index, FLAGS_kinect_camera, FLAGS_kinect_camera_index);
  ```

  C++命令行解析包 gflags 使用问题。在`include\openpose\flags.hpp` 中加入对新flag的定义即可。[参考网页](https://gohalo.me/post/package-gflags-usage.html)

## 项目封存（2023年3月12日）

- **已完成的任务**

  1. 完成了Openpose在linux系统上，加入3D解释器后的源码编译

  2. 初步修改Openpose源码，使得可以通过如下命令行，按指定方式（使用Kinect相机代替Flir相机读取数据）运行程序

     ```
     ./build/examples/openpose/openpose.bin --kinect_camera
     ```

     命令行前为编译`openpose.cpp`完成后的二进制可执行文件，后为指定的FLAG参数。

     具体代码修改可参看GitHub的project仓库的更新记录。

     ---

  3. 安装 **Azure Kinect SDK**，包括查看器与用于后续开发的包。

  4. 运行示例程序，能够通过调用 **k4a** 包中的函数实现相机数据的读取，如内参、点云信息等。

  5. 安装 **ROS** 系统，用于进一步开发。

  6. 使用 **ROS** 和 **openpose** 分别标定 Kinect 摄像头。

- **之后的任务**

  1. 完成KinectReader的编写，使得可以用Kinect代替Flir相机完成3D重建任务，**代码各个函数的实现思路可参考GitHub的project仓库最新的更新记录**。You Can Do It！

  2. 按计划读取Openpose输出的关键点的坐标，并通过与上大学长交流，首先实现二维关键点到三维空间关键点的映射。

  3. 实现高效的三维关键点坐标追踪，使用卡尔曼滤波观测器减小跟踪误差

  4. 引入骨骼框架的约束，配合关键点的追踪先实现一个手臂运动的3D重建

     ---

  5. 开发 Kinect 时，为了将源代码文件链接到对应的头文件（位于），需要编写 **CMakefile** 文档。

  6. 在 **openpose** 中接入 Kinect 的接口（如 k4a），从而能够利用 openpose 直接调用 Kinect SDK 的函数。

- **重要文件的安装位置与使用方法**

  1. Openpose源码编译

     在完成新代码的编写后，使用 cmake 工具在 `openpose-copy\build` 文件夹下完成Configure与Generate，命令为：

     ```
     cmake-gui ..
     ```

     之后使用如下命令，完成编译：

     ```
     make -j`nproc`
     ```

  2. 网卡驱动安装

     参考目录 `~/3d_motion/config/EW-7611ULB_Linux_Driver_1.0.1.2` 下的操作说明即可。

  
  3. 打开 Kinect 查看器：在任意位置 `sudo k4aviewer`
  
  4. 项目的根目录 `/home/threed_motion/3d_motion` ，下属文件夹：
     1. Azure-Kinect-Sensor-SDK：SDK 的安装位置。
     2. 在 `./include/k4a/k4a.h` 中可以查看 Kinect 摄像头使用的函数。
     3. 在 `./examples`中可以查看示例程序。在示例程序所在文件夹下 `cmake` 来编译文件，然后依照 readme 运行。
     4. KinectDK_ws：ROS 的安装位置。
        * 使用 ROS：[戳这里](#2023/2/21)
        * 使用 ROS 标定摄像头：[我来辣](#2023/2/25)
  
  5. KinectProgram 与 KinectVideo
  
     存放编写的 Kinect 程序与拍摄的 Kinect 视频的地方。

## 启动（2023年10月1日）

### openpose三维重建

关键代码：

```c++
namespace op
{
    /**
     * 3D triangulation given known camera parameter matrices and based on linear DLT algorithm.
     * The returned cv::Mat is a 4x1 matrix, where the last coordinate is 1.
     */
    double triangulate(
        cv::Mat& reconstructedPoint, const std::vector<cv::Mat>& cameraMatrices,
        const std::vector<cv::Point2d>& pointsOnEachCamera);

    /**
     * 3D triangulation given known camera parameter matrices and based on linear DLT algorithm with additional LMA
     * non-linear refinement.
     * The returned cv::Mat is a 4x1 matrix, where the last coordinate is 1.
     * Note: If Ceres is not enabled, the LMA refinement is skipped and this function is equivalent to triangulate().
     */
    double triangulateWithOptimization(
        cv::Mat& reconstructedPoint, const std::vector<cv::Mat>& cameraMatrices,
        const std::vector<cv::Point2d>& pointsOnEachCamera, const double reprojectionMaxAcceptable);
}
```

重建方法：

DLT 线性重建 [DLT 直接线性转换算法 | Wayland's Blog (waylandwong.github.io)](https://waylandwong.github.io/dlt/)

### 重写kinectWrapper类

参考如下链接，使用 `k4a.h` 库重写 `kinectWrapper.cpp` 。

安装编译指南：[GitHub - microsoft/Azure-Kinect-Sensor-SDK: A cross platform (Linux and Windows) user mode SDK to read data from your Azure Kinect device.](https://github.com/Microsoft/Azure-Kinect-Sensor-SDK)

库的参考文档：[Azure Kinect Sensor SDK: Reference (microsoft.github.io)](https://microsoft.github.io/Azure-Kinect-Sensor-SDK/master/modules.html)

同步Kinect读取参考：

[基于Kinect Azure的多相机数据采集（一）_多摄像头同步采集-CSDN博客](https://blog.csdn.net/qq_43707919/article/details/109340757)

[基于Kinect Azure的多相机数据采集（二）_kinect相机数据获取-CSDN博客](https://blog.csdn.net/qq_43707919/article/details/109347961)

[同步多个 Azure Kinect DK 设备 | Microsoft Learn](https://learn.microsoft.com/zh-cn/azure/kinect-dk/multi-camera-sync)（存在需要在软件上考虑的影响当前同步状态的因素）

- 在Linux上安装Azure Kinect Sensor SDK时，通过如下设置保证相机设备可以不在root权限下运行程序。

  On Linux, once attached, the device should automatically enumerate and load all drivers. However, in order to use the Azure Kinect SDK with the device and without being 'root', you will need to setup udev rules. We have these rules checked into this repo under 'scripts/99-k4a.rules'. To do so:

  - Copy 'scripts/99-k4a.rules' into '/etc/udev/rules.d/'.
  - Detach and reattach Azure Kinect devices if attached during this process.

  Once complete, the Azure Kinect camera is available without being 'root'.

  也许我可以理解为不需要添加sudo就可以运行摄像头的驱动程序或包含有摄像头驱动包的程序，相比之下遥操作杆的程序是需要添加`sudo` 命令才可以运行的。

- 需要在Kinect SDK中找到的对应元素：

  关键指针：

  - system指针（用于控制整个相机系统）
    - GetCameras：获取相机列表
    - GetInstance(); 与 ReleaseInstance();：实例化
  - Camera指针（用于控制单个相机）
    - GetNextImage()：获取图片
    - GetNodeMap()：获取每个相机的 GenICam 节点映射，相当于一个检索各个相机参数的指针
    - Init()：初始化
    - BeginAcquisition();：开始采集
    - EndAcquisition();：停止采集
    - DeInit();：去初始化

  - Image指针（用于存放相机采集到的图片）

    - convert：图像格式的转换
    - getXPadding：获取图像偏移
    - getwidth：获取图像宽
    - getData：获取图像数据
    - GetStride：图像数据的步幅，即每行数据的字节数
    - IsIncomplete：检查完整性
    - GetImageStatus：获取状态

  - iNodeMap指针（获取并设置相机参数）

### 同步设置

- k4a_device_get_sync_jack() 函数可以检查设备同步线的连接情况
- k4a_device_configuration_t::wired_sync_mode 该参数可以设计相机的主从模式
- k4a_device_get_capture() 函数可以从相机中读取图片到一个 capture_handle 的 Buffer 中

## 2023年10月8号

* ### 重新安装Ubuntu 18.04系统：

  * 下载一个ubuntu系统镜像到U盘中
  * 用Rufus软件制作启动盘
  * 计算机开机时选择U盘启动：先按enter/f1/f12等键进入bios模式，禁用掉secure boot，然后退出bios模式在startup中找到U盘即可，**采用UEFI方式安装较好**
  * 安装Ubuntu

* 恢复2022.11.27的系统备份

  ———————紧急情况———————

  恢复备份之后系统中多出了一个用户，出现了未知错误，崩不住了！

  重新制作启动盘，重新安装！！！

  ——————————————————

* 重新安装之后，先用网线连接网络！

  * 安装基本依赖（代替原先恢复备份的步骤，直接重新开始！）：
    * sudo apt upgrade
    * sudo apt install build-essential
    * sudo apt install cmake

* 安装无线网卡驱动（仅适用于当前型号网卡：realtek 8821cu）：

  https://gitcode.net/mirrors/maxhw/rtl8821cu?utm_source=csdn_github_accelerator

  配置无线网络：

  https://blog.csdn.net/weixin_40358083/article/details/82864220

* 安装显卡驱动：https://blog.csdn.net/weixin_44348719/article/details/125049064

  * 查看显卡型号：此处得到的显卡为 GeForce RTX 3080 Lite Hash Rate
  * `sudo apt-get install lightdm` 一步，会出现一个图形界面，选择lightdm即可。
  * 在第四步进入tty模式后，需要再次输入用户名和密码，记得**提前记住用户名**。

* 安装teamviewer：官网下载即可。[Linux (teamviewer.cn)](https://www.teamviewer.cn/cn/download/linux/)

今日任务完成  又回到最初的起点🎶~

* 再次备份：https://blog.csdn.net/amnesiagreen/article/details/104572812


## 2023年10月9号

### 重新安装kinect SDK：

参考网站：https://learn.microsoft.com/zh-cn/azure/kinect-dk

* 首先要下载几个依赖包，详见教程：[Ubuntu20.04和22.04配置Azure Kinect Sensor SDK-CSDN博客](https://blog.csdn.net/OTZ_2333/article/details/124025953)

  下载好 `libk4a1.4_1.4.1_amd64.deb` `libk4a1.4-dev_1.4.1_amd64.deb` `k4a-tools_1.4.1_amd64.deb`之后，放入项目下同一文件夹，依次解压即可。注意：解压k4a-tools的时候需要先 `apt install libsoundio1`

* 测试一下，输入 `k4aviewer` 即可打开摄像头。

### openpose依赖安装

* 安装CUDA：https://blog.csdn.net/my__blog/article/details/125720601 此处下载的是CUDA11.8

* 安装cudnn：

  下载deb： https://developer.nvidia.com/rdp/cudnn-download

  安装：

  ```bash
  sudo dpkg -i cudnn-local-repo-ubuntu1804-8.9.4.25_1.0-1_amd64.deb 
  sudo apt-get update
  cd /var/cudnn-local-repo-ubuntu1804-8.9.4.25/
  sudo dpkg -i libcudnn8_8.9.4.25-1+cuda11.8_amd64.deb
  sudo dpkg -i libcudnn8-dev_8.9.4.25-1+cuda11.8_amd64.deb 
  sudo dpkg -i libcudnn8-samples_8.9.4.25-1+cuda11.8_amd64.deb 
  ```

  测试安装是否成功(创建一个空闲文件夹并进入该文件夹，执行下述操作)：

  ```bash
  cp -r /usr/src/cudnn_samples_v8/ ./
  cd cudnn_samples_v8/mnistCUDNN/
  sudo make clean
  sudo make
  ```

  测试过程的报错及解决：

  ```
  ERROR:
  test.c:1:10: fatal error: FreeImage.h: No such file or directory
   #include "FreeImage.h"
  
  SOLVE:
  (https://lequ7.com/guan-yu-ubuntu2004ubuntu2004-xian-ka-qu-dong-cudacudnn-guan-wang-an-zhuang-jiao-cheng.html) —— 安装缺少的依赖
  sudo apt-get install g++ freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libglu1-mesa libglu1-mesa-dev
  sudo apt-get install libfreeimage3 libfreeimage-dev
  ```

* 完成代码编译后，运行demo文件出现有关**CUDNN**的报错。

  在新的实验主机上，由于显卡型号改变，为RTX 3080显卡。其所需的最低CUDA版本为`11.x` 。于是在该主机上使用的版本信息为：

  ```
  CUDA: 11.7
  Cudnn: 8.9.4
  ```

  经过查阅资料，在cmake-gui设置时，取消勾选`USE_CUDNN` ，重新编译即可。这会带来显卡内存占用增加的问题，可以通过减小视频分辨率来解决，openpose原文如下：

  ```
  The cuDNN library is not mandatory, but required for full keypoint detection accuracy. In case your graphics card is not compatible with cuDNN, you can disable it by unchecking USE_CUDNN in CMake.
  
  Then, you would have to reduce the --net_resolution flag to fit the model into the GPU memory. You can try values like 640x320, 320x240, 320x160, or 160x80 to see your GPU memory capabilities. After finding the maximum approximate resolution that your GPU can handle without throwing an out-of-memory error, adjust the net_resolution ratio to your image or video to be processed (see the --net_resolution explanation from doc/advanced/demo_advanced.md), or use -1 (e.g., --net_resolution -1x320).
  ```

* 运行demo但是没有任何骨骼点，可能的原因是model没有下载成功。

  可以通过检查openpose文件下models文件的大小来验证，如果有完整的模型，该文件夹大小应该为`734M`左右。

  如果openpose提供的模型下载地址不能访问，可以访问该模型下载链接：

  https://www.kaggle.com/datasets/changethetuneman/openpose-model/

  之后根据models文件中模型的名称，将空壳模型替换为下载到的完整模型即可。

* 加入3d解释器的模型编译：

  首先需要根据 [官网](http://ceres-solver.org/installation.html#linux) 安装Ceres的必要依赖，之后根据参考[网址](https://blog.csdn.net/qq_41586768/article/details/107541917)安装1.14版本的Ceres。

  完成上述工作后，重新打开cmake-gui，勾选：

  - WITH_3D_RENDERER
  - WITH_CERES
  - WITH_EGIEN: AUTOBUILD

  重新进行设置与编译，出现的后续问题可以参考之前日志（23年2月19日）的记录。

## 2023年10月10号

将图片转换为opencv matrix：[How to convert k4a_image_t to opencv matrix? (Azure Kinect Sensor SDK) - Stack Overflow](https://stackoverflow.com/questions/57222190/how-to-convert-k4a-image-t-to-opencv-matrix-azure-kinect-sensor-sdk)

- 完成了kinectWrapper的撰写

## 2023年10月11号

### 探究如何编译Kinect SDK并在项目中实现库的引用

* 继续玩vscode！

  * 安装组件：C/C++; C/C++ Snippets; Code Runner; Include Autocomplete
  * 跑通了HelloWorld！
  * 尝试include kinect的库时出现了问题！发现k4a.lib和k4a.dll缺失，原因是没有编译SDK的源码......之前安装的k4aviewer只是相当于一个软件，无法进行代码开发。（之前在2月18号已经做过一次SDK源码的编译，但是我忘力（悲）

* 编译Kinect SDK源码：[Azure-Kinect-Sensor-SDK/docs/building.md at develop · microsoft/Azure-Kinect-Sensor-SDK · GitHub](https://github.com/microsoft/Azure-Kinect-Sensor-SDK/blob/develop/docs/building.md)

  首先**下载源码**到文件夹中：`git clone https://github.com/microsoft/Azure-Kinect-Sensor-SDK.git`

  在编译之前需要**准备好依赖**，在 *Azure-Kinect-Sensor-SDK/scripts/docker* 中给出了三种安装依赖的方式：Dockerfile、setup-ubuntu.sh以及依照sources.list手动安装。这里采用第二种方法，参考[Ubuntu18.04+Azure Kinect DK配置全过程（SDK源码+ROS）_azure kinect dk + ros18.04-CSDN博客](https://blog.csdn.net/qq_27399933/article/details/107356117?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-107356117-blog-124025953.235^v38^pc_relevant_sort_base3&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-107356117-blog-124025953.235^v38^pc_relevant_sort_base3&utm_relevant_index=1)

  ```bash
  sudo chmod +x setup-ubuntu.sh
  ./setup-ubuntu.sh
  ```

  然后就是**编译**了！编译过程中会自动下载一些东西，其中libyuv包无法下载，需要修改下载源：

  在根目录（Azure-Kinect-Sensor-SDK）中`ls -a` 查看所有文件，找到被隐藏的.gitmodules，然后将libyuv的下载地址改为 `https://github.com/lemenkov/libyuv.git`

  开始编译：

   ```bash
  mkdir build
  cd build
  cmake .. -GNinja -DCMAKE_BUILD_TYPE=Debug
  ninja
   ```

  最后将SDK中的动态链接库等相关文件安装到系统目录中供其他项目使用：

  `sudo ninja install`

  至此编译完成，应该可以调用lib了……吧？

  NO！突然发现，Linux系统中没有.lib后缀名，而是用.so表示动态链接库！！（.a表示静态链接库）

  有关k4a的链接库在 `/usr/local/lib` 中！

* 记住头文件和链接库的位置： `/usr/include/k4a` 和 `/usr/local/lib`

* 用vscode编写自己的kinect程序

  * 在项目文件夹中运行 `code .` 打开vscode， `.` 表示以当前文件夹作为vscode项目目录。

  * 创建cpp文件，开始写代码！

  * 在cpp文件开头引用k4a相关库，如 `#include<k4a/k4a.h>`

  * 点击Terminal -> Configure Default Build Task创建tasks.json，这是后续编译的关键。一般选择C/C++ : g++ build active file

  * **在tasks.json的args参数中，添加：**

    ```
    "-L/usr/local/lib",
    "-lk4a"
    ```

    -L指定了链接库所在的文件夹， 而-l指定了具体用到的链接库。

  * 点击View -> Command Palette（或快捷键ctrl+shift+P）-> C/C++: Edit Configurations (UI) **创建c_cpp_properties.json，在includePath参数中添加：**

    ```
    "/usr/include/k4a"
    ```

  * 回到cpp文件，点击Terminal -> Run Build Task（或快捷键ctrl+shift+B）即可在同一文件夹下构建可执行文件。

## 2023年10月13号

### 修改openpose源码的CMakeList文件引入Azure Kinect SDK

在从源码中编译Kinect SDK后，确保在ubuntu中可以找到`k4a.lib`文件。

- 增加cmake-gui编译选项，并设置编译define

  ```cmake
  option(WITH_KINECT_CAMERA "Add KINECT camera code (requires Azure Kinect SDK already installed)." OFF)
  
  if (WITH_KINECT_CAMERA)
    # OpenPose flags
    add_definitions(-DUSE_KINECT_CAMERA)
  endif (WITH_KINECT_CAMERA)
  ```

- 查找 K4A 库

  ```cmake
  if (WITH_AZURE_KINECT)
    # Azure Kinect SDK
    find_package(k4a REQUIRED)
    if (NOT k4a_FOUND)
      message(FATAL_ERROR "Azure Kinect SDK not found. Either turn off the `WITH_AZURE_KINECT` option or specify the path to
        the Azure Kinect SDK includes and libs.")
    endif (NOT k4a_FOUND)
  endif (WITH_AZURE_KINECT)
  ```

- 将头文件加入项目

  ```cmake
  if (WITH_AZURE_KINECT)
      include_directories(SYSTEM ${K4A_INCLUDE_DIRS})
  endif (WITH_AZURE_KINECT)
  ```

- 在链接阶段将 k4a 库链接到 OpenPose 项目中

  ```cmake
  if (WITH_AZURE_KINECT)
      set(OpenPose_3rdparty_libraries ${OpenPose_3rdparty_libraries} ${K4A_LIB})
  endif (WITH_AZURE_KINECT)
  ```

#### 报错：

```bash
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_capture_get_color_image'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_start_cameras'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_get_device_timestamp_usec'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_get_width_pixels'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_close'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_get_serialnum'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_open'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_reference'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_get_installed_count'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_release'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_capture_release'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_get_capture'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_set_color_control'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_stop_cameras'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_get_sync_jack'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_get_height_pixels'
../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_get_buffer'
collect2: error: ld returned 1 exit status
examples/tutorial_api_cpp/CMakeFiles/02_whole_body_from_image_default.bin.dir/build.make:175: recipe for target 'examples/tutorial_api_cpp/02_whole_body_from_image_default.bin' failed
make[2]: *** [examples/tutorial_api_cpp/02_whole_body_from_image_default.bin] Error 1
CMakeFiles/Makefile2:1254: recipe for target 'examples/tutorial_api_cpp/CMakeFiles/02_whole_body_from_image_default.bin.dir/all' failed
make[1]: *** [examples/tutorial_api_cpp/CMakeFiles/02_whole_body
```

解决方法：

`-lk4a` 是告诉链接器使用名为 `k4a` 的库的标志，缺少这个标志可能导致链接错误。

```cmake
if (WITH_AZURE_KINECT)
    set(OpenPose_3rdparty_libraries ${OpenPose_3rdparty_libraries} ${K4A_LIB} -lk4a)
endif (WITH_AZURE_KINECT)
```

### 进行相机标定

openpose参考网站：[openpose/doc/advanced/calibration_module.md at master · CMU-Perceptual-Computing-Lab/openpose · GitHub](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/advanced/calibration_module.md)

### kinectWrapper报错

- 在代码执行期间产生如下有关USB的报错：

  ```bash
  ibusb_claim_interface(usbcmd->libusb, usbcmd->interface) returned LIBUSB_ERROR_BUSY in usb_cmd_create
  ```

  原因为在代码中在没有调用close函数的情况下，多次调用open函数：

  ```c++
  k4a::device::open(i);
  
  k4a::device::close();
  ```

  在一轮完整wrapper过程中，open函数只能被调用一次，之后如需要使用device_handle，使用引用传递即可。

- `k4a::device`类中没有拷贝构造函数，其代码呈现如下：

  ```c++
  device(const device&) = delete
  ```

  这是一个 C++ 中的特殊声明，用于删除（`= delete`）拷贝构造函数。这种声明告诉编译器不允许使用拷贝构造函数创建该类的对象的副本。

  这样的设计通常出现在需要精确地控制对象的拷贝行为的情况下。例如，如果一个类管理了资源（比如内存或文件句柄），通过禁用拷贝构造函数可以防止意外的资源共享或释放。在现代 C++ 中，通常推荐使用移动语义来代替拷贝，因为移动操作更高效且更适合具有资源管理职责的类。

## 2023年10月15号

### 同步代码DEBUG

- 运行MultiDeviceCapture的start_camera函数，会找不到sub_device的handle。

  原因：在执行MultiDeviceCapture的DeInit函数时，没有将附属设备向量进行clear操作，导致之后的Init操作在已经变成空指针的device handle后添加了新的device handle。这也导致sub_devices vector中元素个数比实际的附属设备个数多，从而在之后进行start_camera时访问到了空指针的device handle

### 外参标定

设备同步问题搞定后（jy yyds！）同时连接三台kinect并插上同步线，然后**收集图片**：

`./build/examples/openpose/openpose.bin --kinect_camera --frame_undistort --write_images ./extrinsic_images`

这会同时为三台kinect拍摄图片，按照 `number_rendered.png number_rendered_1.png number_rendered_2.png`的形式存储，一组三张。

接着**开始标定**。标定外参时，以其中一个kinect的相机坐标系为世界坐标系原点，然后分别计算其余kinect相对其的旋转矩阵R和平移矩阵t。（理论：对于单目摄像机，没有必要标定其外参（或者说其拍摄的每一张图片都对应一个外参），因为完全可以让相机光心坐标系与世界坐标系重合；也因此单目摄像机无法完成三维的重建）

```bash
./build/examples/calibration/calibration.bin --mode 2 --grid_square_size_mm 100.0 --grid_number_inner_corners "9x6" --omit_distortion --calibration_image_dir ./extrinsic_images/ --cam0 0 --cam1 1 --camera_parameter_folder ./models/cameraParameters/kinect/
```

注意要加上camera_parameter_folder的flag！否则默认的参数文件路径为`models/cameraParameters/flir/`，会报错：

```bash
vector::\_M\_range\_check: \_\_n(which is 1) >= this -> size() (which is 0)
```

建议拍摄250组以上图片获得好的标定效果。

## 2023年10月22号

**（待可为提交）**

## 2023年10月26号

### 结题报告（ddl：11月12号）无字数要求

- 项目研究内容 —— kw
- 项目研究方案 
- 项目完成情况 —— kw
- 项目特色与创新
- 项目研究取得的成果 —— kw
- 项目成员贡献排序与工作备注
- 项目还存在哪些问题，有哪些建议。
- 项目研究心得 —— kw

### 项目研究论文（ddl：11月12号）10000字

（研究内容、方法及研究成果）

- 引言 —— kw
- 项目元素介绍
  - 三维重建[3D 人体姿态估计简述 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/400922771)
  - Openpose项目
  - 相机标定原理 —— kw
  - Azure Kinect —— kw
  
- 研究工作（猛猛把日志内容扩写）
  - 工作流程
  - 环境配置 —— kw
  - 源码修改
  - 参数标定 —— kw
- 应用场景与社会效益
- 总结

### 项目研究综述（ddl：11月12号）2000字

（创新点、特色和应用及推广前景）

- 研究背景和方向（上文引言）
- 研究理论基础（上文元素介绍）
- 实验过程（上文研究工作）
- 应用与推广前景（上文应用场景）
- 总结（上文总结）

### 个人总结（ddl：11月12号）2000字

（**每人一份**，可以放照片）

（承担的工作，发挥的作用，以及在能力培养和素质提高特别是在创新思维和创新实践方面的体验和收获）

## 2023年11月18号

### 结项答辩ppt

- 项目背景

  - 研究目的（Introduction）  **一页**

    应用前景，放一些图，简单一笔带过

  - 相关工作（related works）  **一页**

    放几张图（对应项目论文中“三维重建”部分），简单介绍引出我们所选用的重建方案

  - 问题陈述（Problem statement）（可以理解为项目的理论支撑）

    - Openpose项目  **一页**

      简单介绍Openpose（对应项目论文中的“Openpose项目”），一页，重点讲一下PCM与PAF的概念以及2D识别最后可以得到的结果是什么。

    - Kinect Aurez Camera  **一页**

      简单介绍相机的功能，重点说三个特点：SDK、同步功能、深度相机（虽然我们没用，但是可以提及一下）

    - 相机标定  **一页**

      简单介绍使用的标定方法，重点讲清楚标定得到了的矩阵：内参矩阵与外参矩阵

---

- 研究工作（Experiment）

  - 环境配置与代码部署  **一页**
  - 学习并熟悉SDK的使用  **一页**
  - 扩展Openpose源代码  **一页**
  - 系统搭建与相机标定  **一页**

- 研究成果（Result）

  - 成果评价  **一页**

    项目视频、项目实现的指标、项目的缺陷

- 研究总结（Conclusion）

  - 项目展望  **一页**

    可能的改进方法、可以优化扩展的代码提交到Openpose的分支

  - 致谢  **一页**

    套话，自己能力得到了什么锻炼，感谢陪伴一路的伙伴，感谢老师的指导与学生创新中心的支持。

  

​	
