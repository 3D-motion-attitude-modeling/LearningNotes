# 项目日志

## 2022/11/27

### Openpose

使用openpose调用网络摄像头（openpose中没有提供kinect相机的接口，因此暂时只能用网络摄像头的接口来查看kinect实时画面），并且保存相机画面的2D人体姿态点。

连接网络摄像头：

1. 查看是否有摄像头usb驱动：`ls /dev/v*` 如果结果含有 `/dev/video0` 则有。

2. 查看usb信息： `lsusb` 查看哪一个是连接的摄像头。

   经查，kinect摄像头ID为 `045e:097a~e` 

保存姿态点方法教程：https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc

* cmd方法：在 `~/3d_motion/openpose/openpose` 目录下输入命令，注意退出conda： `conda deactivate`
* 得到姿态点（2d）：保存为 `.json` 文件，注意专门准备一个文件夹存放，因为它会保存每一帧的姿态点。

 ### Linux

#### 问题与解决方法

- 问题：桌面卡死
- 解决方法：`ctrl+alt+T` 打开一个新的命令行，输入 `sudo pkill Xorg` 注销桌面，重新登陆用户即可。**不要直接重启！！** 



## 2023/2/17

### Kinect

安装了Azure Kinect SDK，教程来自官方文档：[快速入门 - 设置 Azure Kinect DK | Microsoft Learn](https://learn.microsoft.com/zh-cn/azure/kinect-dk/set-up-azure-kinect-dk)

kinect使用的主要文件的安装位置：

* `k4aviewer  /usr/bin/k4aviewer `
* `k4a.h /usr/include/k4a/k4a.h`

#### 问题与解决方法

* 问题：打开kinect查看器时报错 `Is the device being used by another application?`
* 解决方法：开启kinect时需要管理员权限。使用 `sudo k4aviewer`指令打开。



## 2023/2/18

### Kinect

为了进一步使用SDK进行开发，下载了完整的Kinect SDK源码。其附带example程序，能够帮助我们学习使用k4a库函数。在编译好SDK之后，成功运行了example中的测试程序。

#### 问题与解决方法

* 问题1：编译SDK时报错
* 解决方法：cmake前需要手动下载一项（文档中有），下载好之后再cmake。报错没关系，只要检查 `/extern/libusb` 等文件夹中已经下载好文件即可进行后续步骤。
* 问题2：编译测试程序失败，cmake时报错：找不到 k4a::k4a
* 解决方法： 在`/examples/CMakelists.txt` 中添加 `find_package(k4a REQUIRED)` 等语句。这个问题涉及到c++文件的链接、编译过程，需要进一步学习。

## Openpose

重新编译Openpose代码，并阅读学习源代码。

Openpose源代码理解：

* `std::make_shared <FlirReader> (cameraParameterPath, cameraResolution, undistortImage, std::stoi(producerString));`

  上述代码表示生成一个`shared_ptr` , 该指针指向一个数据类型为 `FlirReader` 的数据，括号内为对应数据的构造函数所需参数。


  - ```c++
    // If custom user Worker in same thread
    else if (!userInputWs.empty())
    workersAux = mergeVectors(userInputWs, workersAux);
    // If OpenPose producer (same thread)
    else if (datumProducerW != nullptr)
    workersAux = mergeVectors({datumProducerW}, workersAux);
    ```

​		这行代码表明 `userInputWs` 和 `{datumProducerW}` 为同一个类型。

#### 问题与解决方法

* 问题：编译openpose代码时报错：`nvcc fatal : Unsupported gpu architecture 'compute_80'`

* 解决方法：
* 查阅资料得知，是当前电脑显卡算力不支持8.0。经过查找[Nvidia官网](https://developer.nvidia.com/cuda-gpus)，显卡Quadro P4000的算力为6.1。解决方法参考[网站](https://blog.csdn.net/haiy2011/article/details/128968934)，在 `openpose/cmake/Cuda.cmake` 文件夹，将不支持的算力注释掉即可。


### 

## 2023/2/19

### Openpose

编译openpose的3D解释器：在加入 `WITH_3D_RENDERER` 和 `WITH_CERES` 的标志后重新编译openpose源代码。

#### 问题与解决方法

* 问题1：BUG:  `error: 'integer_sequence' is not a member of  'std'`

* 解决方法：经过查询信息，发现当前安装的 ceres-solver 版本不匹配。当使用当前 [官网](http://ceres-solver.org/installation.html#linux) 下载的版本（ `ceres-solver-2.1.0` ）将出现上述问题。解决方法是安装旧版本的ceres-solver, 大致过程为卸载新版的ceres-solver，之后安装1.14.0版本即可。具体操作参考[网址](https://blog.csdn.net/qq_41586768/article/details/107541917)，其中 **编译ceres_curve_fiiting** 步骤不需要操作。

* 问题2：BUG:

  ```xml
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutSolidSphere'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutDisplayFunc'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutGetModifiers'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutLeaveMainLoop'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutInitWindowPosition'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutSwapBuffers'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutInitWindowSize'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutSolidCone'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutMouseFunc'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutMainLoopEvent'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutPostRedisplay'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutCreateWindow'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutInit'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutKeyboardFunc'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutMotionFunc'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `glutInitDisplayMode'
  collect2: error: ld returned 1 exit status
  examples/deprecated/CMakeFiles/tutorial_api_thread_2_user_input_processing_output_and_datum.bin.dir/build.make:176: recipe for target 'examples/deprecated/tutorial_api_thread_2_user_input_processing_output_and_datum.bin' failed
  make[2]: *** [examples/deprecated/tutorial_api_thread_2_user_input_processing_output_and_datum.bin] Error 1
  CMakeFiles/Makefile2:1176: recipe for target 'examples/deprecated/CMakeFiles/tutorial_api_thread_2_user_input_processing_output_and_datum.bin.dir/all' failed
  make[1]: *** [examples/deprecated/CMakeFiles/tutorial_api_thread_2_user_input_processing_output_and_datum.bin.dir/all] Error 2
  make[1]: *** Waiting for unfinished jobs....
  
  ```


* 解决方法：-lGLU -lGL -lglut没有与编译器链接。参考[gitHub上Openpose的Issues](https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/440)，解决问题的关键是修改Openpose目录下的 `CMakeLists.txt` 文件，将如下代码从

  ```cmake
  if (WITH_3D_RENDERER)
    set(OpenPose_3rdparty_libraries ${OpenPose_3rdparty_libraries} ${GLUT_LIBRARY} ${OPENGL_LIBRARIES})
  endif (WITH_3D_RENDERER) 
  ```

  修改为：

  ```cmake
  if (WITH_3D_RENDERER)
    set(OpenPose_3rdparty_libraries ${OpenPose_3rdparty_libraries} ${GLUT_LIBRARY} ${OPENGL_LIBRARIES} -lGLU -lGL -lglut)
  endif (WITH_3D_RENDERER) 
  ```

  即可成功链接。

* 总结：今天的debug环节中，ChatGPT虽然没有给出任何一个可以解决问题的方案，但是通过合理营造语境描述错误信息，**可以帮助理解问题产生的原因，以及相关陌生代码文件或是陌生命令行指令**，从而间接的帮助问题的解决。

### Linux

在linux上安装了QQ，用于实时与另一台设备进行信息通讯。

### Kinect

学习相机标定知识

* 相机将三维世界中的物体记录在二维的图片中，因此，可以认为相机是一个函数，输入是三维场景，输出为二维图像。**相机标定**就是找到一个合适的数学模型来描述这个函数。这样，我们就可以利用它的反函数，由二维图像重建三维场景。

  ![](D:\2023-2024-1\大创项目-3D姿态检测\github\LearningNotes\pictures\pictures for kw\相机标定原理.png)

* **坐标系**

  为了得到数学模型，我们需要使用坐标系：

  * **世界坐标系(world coordinate system)** 现实世界的绝对坐标系，以现实三维空间中某一点为原点建系，描述相机和物体的坐标。 用 `(Xw, Yw, Zw)` 表示坐标值。

  * **相机(camera)坐标系** 以相机的光心为原点的坐标系，描述物体相对于相机光心的位置。用 `(Xc, Yc, Zc)` 表示坐标值，相机的光轴为Z轴，X、Y轴分别平行于图像坐标系的X、Y轴。

    **光心** 大多数相机都是利用小孔成像原理。将相机透镜组抽象为一个小孔模型，小孔中心即为光心。

  * **图像(image)坐标系** 以CCD图像（即相机拍摄到的原始图像）中心为坐标原点，描述图片中像素的位置。用 `(x, y)` 表示坐标值，单位为现实物理长度（如毫米）。

  * **像素(pixel)坐标系** 以数字图像的左上角为坐标原点，描述图片中像素的位置。用 `(u, v)` 表示坐标值，单位为个（像素个数）

    **原始图像 -> 数字图像** 相机拍摄的图片包含若干像素，每个像素点有它的颜色。数字图像用数字表示每个点的颜色。

![](D:\2023-2024-1\大创项目-3D姿态检测\github\LearningNotes\pictures\pictures for kw\图像坐标系与像素坐标系.png)

* 内参矩阵

  采用齐次坐标，使用矩阵将上式表示为

  ![](D:\2023-2024-1\大创项目-3D姿态检测\github\LearningNotes\pictures\pictures for kw\图像坐标系到像素坐标系.jpg)

  其中 `(u0, v0)` 是图像坐标系原点在像素坐标系中的坐标（由上述定义可知，坐标为图像分辨率的一半），`dx` 和 `dy` 分别为每个像素在图像平面对应方向上的物理尺寸。

  相机坐标系到图像坐标系的转换，如下图：

  ![](D:\2023-2024-1\大创项目-3D姿态检测\github\LearningNotes\pictures\pictures for kw\相机坐标系到图像坐标系.jpg)

  上式中XYZ为物体在相机坐标系中的位置，为具体数值。

  结合上述两个变换，我们得到**内参矩阵**
  $$
  M=
  \begin{bmatrix}
  \frac{1}{dx} & 0 & u0 \\
  0 & \frac{1}{dy} & v0 \\
  0 & 0 & 1
  \end{bmatrix}
  \begin{bmatrix}
  f & 0 & 0 \\
  0 & f & 0 \\
  0 & 0 & 1
  \end{bmatrix}
  =
  \begin{bmatrix}
  f_x & 0 & u0 \\
  0 & f_y & v0 \\
  0 & 0 & 1
  \end{bmatrix}
  $$
  其中 fx，fy 表示在相机拍摄的图像中，长度等于焦距 f 的一段中包含的像素点个数。称 M 为内参矩阵，是因为矩阵 M 的各个元素值只与相机内部参数有关。**利用内参矩阵，可以方便地从相机坐标系变换到像素坐标系。**

* **外参矩阵**

  要得到世界坐标系到像素坐标系的变换，则需要知道这两个三维坐标系之间的相对旋转矩阵 **R** (3×3)和相对位移矩阵 **T** (3×1)。用矩阵表示变换：

  ![](D:\2023-2024-1\大创项目-3D姿态检测\github\LearningNotes\pictures\pictures for kw\外参矩阵.png)

  综上，即可实现完整的变换。上式中，Z~c~ 为物体到光心的距离，即**深度距离**！

* **畸变模型**

  实际的相机并不是完美的小孔成像模型，因此实际成像会有畸变。畸变包括**径向畸变**和**切向畸变**等，是由于焦平面上不同区域对图像的放大率不同形成的画面扭曲变形的现象。

  使用3个畸变参数矫正径向畸变（原理：以光心为圆心，r=0处泰勒展开取前几项）
  $$
  x_{rcorr}=x_p(1+k_1r^2+k_2r^4+k_3r^6) \\
  y_{rcorr}=y_p(1+k_1r^2+k_2r^4+k_3r^6)
  $$
  使用2个畸变参数描述切向畸变
  $$
  x_{tcorr}=x_p+[2p_1x_py_p+p_2(r^2+2x_p^2)] \\
  y_{tcorr}=y_p+[p_1(r^2+2y_p^2)+2p_2x_py_p]
  $$



## 2023/2/21

### Kinect

安装ROS，ROS的功能比Kinect查看器更全面。

安装步骤：（项目结束后注释：在后续工作中，并没有进一步使用ROS）

* 官网教程 https://github.com/microsoft/Azure_Kinect_ROS_Driver，注意当前 Kinect 版本为1.4.1

* 使用以下命令（来自 https://blog.csdn.net/haiyinshushe/article/details/84256137）

  1. `sudo sh -c '. /etc/lsb-release && echo "deb http://mirrors.ustc.edu.cn/ros/ubuntu/ $DISTRIB_CODENAME main" > /etc/apt/sources.list.d/ros-latest.list'`

  2. `sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key 421C365BD9FF1F717815A3895523BAEEB01FA116`

     如果不行，中间的hkp密钥部分可以使用 `hkp://ha.pool.sks-keyservers.net:80  或  hkp://pgp.mit.edu:80`

  3. `sudo apt-get update`

  4. `sudo apt-get install ros-melodic-desktop-full`

  5. 初始化rosdep

     `sudo apt-get install python-rosdep`

     `sudo rosdep init`

     `rosdep update`

  6. 添加ros环境变量

     `echo "source /opt/ros/melodic/setup.bash" >> ~/.bashrc
     source ~/.bashrc`

  7. 安装rosinstall

  至此ROS安装完成。

* 安装 Kinect ROS http://t.csdn.cn/rRdsC

  1. 下载ROS驱动

     `mkdir -p ~/KinectDK_ws/src
     cd ~/KinectDK_ws/src
     catkin_init_workspace
     git clone https://github.com/microsoft/Azure_Kinect_ROS_Driver.git`

  2. 下载 libk4a 和 libk4a-dev 文件（版本1.4.1）https://packages.microsoft.com/ubuntu/18.04/prod/pool/main/libk/libk4a1.2/

  3. 创建文件夹存放上述文件

     `cd ~/KinectDK_ws/src
     mkdir -p ext/sdk`

     在sdk文件夹下再创建3个文件夹：

     1. bin文件夹: 把编译 SDK 时 build 文件夹里面的那个 bin 文件夹直接拷贝过来
     2. include文件夹：SDK 源码里的include文件夹与从 deb 文件里提取出的 include 文件夹合并，拷贝过来
     3. lib文件夹：从deb文件里提取出的两个lib文件夹合并，拷贝过来 **注意：这里是两个lib文件**

     **注：打开deb文件的方法** 不要解压，右键选择 `Open with other application` 再选择 `Archive Manager`

  4. 编译及启用

     `cd ~/KinectDK_ws
     catkin_make
     catkin_make install
     source ./devel/setup.bash
     roslaunch azure_kinect_ros_driver driver.launch `

     `rviz`

     catlin_make install 一步会报错，原因不明。不会影响后续操作（也许）


#### 问题与解决方法

* 问题：`rviz` 开启ROS失败
* 解决方法：`rviz` 需要在与`roslaunch`之外的另一个命令行中开启，同时退出conda环境。



## 2023/2/25

### Openpose

修改Openpose源码，加入KinectCamera标志。

#### 问题与解决方法

* 问题1：编译错误：`Syntax error: "(" unexpected`

* 解决方法：将源码文件夹名从 `Openpose(copy)` 改为  `Openpose-copy` 即可

* 问题2：编译错误：

  ```xml
  error: ‘FLAGS_kinect_camera’ was not declared in this scope
               FLAGS_flir_camera, FLAGS_flir_camera_index, FLAGS_kinect_camera, FLAGS_kinect_camera_index);
  ```


* 解决方法：C++命令行解析包 gflags 使用问题。在`include\openpose\flags.hpp` 中加入对新flag的定义即可。[参考网页](https://gohalo.me/post/package-gflags-usage.html)

### Kinect

使用Openpose的标定模块来标定Kinect摄像头**内参**。[官方教程](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/advanced/calibration_module.md#introduction)，最好拍摄150张以上的图片保证标定效果。

#### 问题与解决方法

* 问题：报错 `image could not be opened!`
* 解决方法：使用Openpose调用Kinect摄像头拍摄标定所用的照片，结束拍摄时最后一张照片是不完整的，无法读取。**将最后一张照片删除即可**。



## 2023/3/12

由于需要准备保研等事情，项目暂时封存。总结了已完成的任务，并敲定后续的工作安排：

- **已完成的任务**

  1. 完成了Openpose在linux系统上，加入3D解释器后的源码编译

  2. 初步修改Openpose源码，使得可以通过如下命令行，按指定方式（使用Kinect相机代替Flir相机读取数据）运行程序：

     ```
     ./build/examples/openpose/openpose.bin --kinect_camera
     ```

     命令行前为编译`openpose.cpp`完成后的二进制可执行文件，后为指定的FLAG参数。

     具体代码修改可参看GitHub的project仓库的更新记录。

     ---

  3. 安装 **Azure Kinect SDK**，包括查看器与用于后续开发的包。

  4. 运行示例程序，能够通过调用 **k4a** 包中的函数实现相机数据的读取，如内参、点云信息等。

  5. 安装 **ROS** 系统，用于进一步开发。

  6. 使用 **ROS** 和 **openpose** 分别标定 Kinect 摄像头。

- **之后的任务**

  1. 完成KinectReader的编写，使得可以用Kinect代替Flir相机完成3D重建任务，**代码各个函数的实现思路可参考GitHub的project仓库最新的更新记录**。You Can Do It！

  2. 按计划读取Openpose输出的关键点的坐标，并通过与上大学长交流，首先实现二维关键点到三维空间关键点的映射。

  3. 实现高效的三维关键点坐标追踪，使用卡尔曼滤波观测器减小跟踪误差

  4. 引入骨骼框架的约束，配合关键点的追踪先实现一个手臂运动的3D重建

     ---

  5. 开发 Kinect 时，为了将源代码文件链接到对应的头文件（位于），需要编写 **CMakefile** 文档。

  6. 在 **openpose** 中接入 Kinect 的接口（如 k4a），从而能够利用 openpose 直接调用 Kinect SDK 的函数。



## 2023/10/1

### Openpose

学习了openpose的三维重建方法，并重写openpose代码中的kinectWrapper类。

#### 三维重建

关键代码：

```c++
namespace op
{
    /**
     * 3D triangulation given known camera parameter matrices and based on linear DLT algorithm.
     * The returned cv::Mat is a 4x1 matrix, where the last coordinate is 1.
     */
    double triangulate(
        cv::Mat& reconstructedPoint, const std::vector<cv::Mat>& cameraMatrices,
        const std::vector<cv::Point2d>& pointsOnEachCamera);

    /**
     * 3D triangulation given known camera parameter matrices and based on linear DLT algorithm with additional LMA
     * non-linear refinement.
     * The returned cv::Mat is a 4x1 matrix, where the last coordinate is 1.
     * Note: If Ceres is not enabled, the LMA refinement is skipped and this function is equivalent to triangulate().
     */
    double triangulateWithOptimization(
        cv::Mat& reconstructedPoint, const std::vector<cv::Mat>& cameraMatrices,
        const std::vector<cv::Point2d>& pointsOnEachCamera, const double reprojectionMaxAcceptable);
}
```

重建方法：

DLT 线性重建 https://waylandwong.github.io/dlt/

#### 重写kinectWrapper类

参考如下链接，使用 `k4a.h` 库重写 `kinectWrapper.cpp` 。

安装编译指南：[GitHub - microsoft/Azure-Kinect-Sensor-SDK: A cross platform (Linux and Windows) user mode SDK to read data from your Azure Kinect device.](https://github.com/Microsoft/Azure-Kinect-Sensor-SDK)

库的参考文档：[Azure Kinect Sensor SDK: Reference (microsoft.github.io)](https://microsoft.github.io/Azure-Kinect-Sensor-SDK/master/modules.html)

同步Kinect读取参考：

[基于Kinect Azure的多相机数据采集（一）_多摄像头同步采集-CSDN博客](https://blog.csdn.net/qq_43707919/article/details/109340757)

[基于Kinect Azure的多相机数据采集（二）_kinect相机数据获取-CSDN博客](https://blog.csdn.net/qq_43707919/article/details/109347961)

[同步多个 Azure Kinect DK 设备 | Microsoft Learn](https://learn.microsoft.com/zh-cn/azure/kinect-dk/multi-camera-sync)（存在需要在软件上考虑的影响当前同步状态的因素）

- 在Linux上安装Azure Kinect Sensor SDK时，通过如下设置保证相机设备可以不在root权限下运行程序。

  On Linux, once attached, the device should automatically enumerate and load all drivers. However, in order to use the Azure Kinect SDK with the device and without being 'root', you will need to setup udev rules. We have these rules checked into this repo under 'scripts/99-k4a.rules'. To do so:

  - Copy 'scripts/99-k4a.rules' into '/etc/udev/rules.d/'.
  - Detach and reattach Azure Kinect devices if attached during this process.

  Once complete, the Azure Kinect camera is available without being 'root'.

  *理解：不需要添加sudo就可以运行摄像头的驱动程序或包含有摄像头驱动包的程序，相比之下遥操作杆的程序是需要添加`sudo` 命令才可以运行的。*

- 在Kinect SDK中找到的对应元素：

  关键指针：

  - system指针（用于控制整个相机系统）
    - GetCameras：获取相机列表
    - GetInstance(); 与 ReleaseInstance();：实例化
  - Camera指针（用于控制单个相机）
    - GetNextImage()：获取图片
    - GetNodeMap()：获取每个相机的 GenICam 节点映射，相当于一个检索各个相机参数的指针
    - Init()：初始化
    - BeginAcquisition();：开始采集
    - EndAcquisition();：停止采集
    - DeInit();：去初始化

  - Image指针（用于存放相机采集到的图片）

    - convert：图像格式的转换
    - getXPadding：获取图像偏移
    - getwidth：获取图像宽
    - getData：获取图像数据
    - GetStride：图像数据的步幅，即每行数据的字节数
    - IsIncomplete：检查完整性
    - GetImageStatus：获取状态

  - iNodeMap指针（获取并设置相机参数）

#### 同步设置

- k4a_device_get_sync_jack() 函数可以检查设备同步线的连接情况
- k4a_device_configuration_t::wired_sync_mode 该参数可以设计相机的主从模式
- k4a_device_get_capture() 函数可以从相机中读取图片到一个 capture_handle 的 Buffer 中



## 2023/10/8

### 系统搭建

由于项目停滞时间较长，此前所用设备已经被回收，需要重新申请设备、安装系统与配置环境。

#### 安装Ubuntu 18.04系统

* 下载一个ubuntu系统镜像到U盘中
* 用Rufus软件制作启动盘
* 计算机开机时选择U盘启动：先按enter/f1/f12等键进入bios模式，禁用掉secure boot，然后退出bios模式在startup中找到U盘即可，**采用UEFI方式安装较好**
* 安装Ubuntu

#### 安装依赖、驱动、软件

* 安装基本依赖（先用网线连接网络）：

  * sudo apt upgrade
  * sudo apt install build-essential
  * sudo apt install cmake

* 安装无线网卡驱动（仅适用于当前型号网卡：realtek 8821cu）：

  https://gitcode.net/mirrors/maxhw/rtl8821cu?utm_source=csdn_github_accelerator

  配置无线网络：

  https://blog.csdn.net/weixin_40358083/article/details/82864220

* 安装显卡驱动：https://blog.csdn.net/weixin_44348719/article/details/125049064

  * 查看显卡型号：此处得到的显卡为 GeForce RTX 3080 Lite Hash Rate
  * `sudo apt-get install lightdm` 一步，会出现一个图形界面，选择lightdm即可。
  * 在第四步进入tty模式后，需要再次输入用户名和密码，记得**提前记住用户名**。

* 安装teamviewer：官网下载即可。[Linux (teamviewer.cn)](https://www.teamviewer.cn/cn/download/linux/)



## 2023/10/9

### Kinect

重新安装Kinect SDK。参考网站：https://learn.microsoft.com/zh-cn/azure/kinect-dk

* 首先要下载几个依赖包：[教程](https://blog.csdn.net/OTZ_2333/article/details/124025953)

  下载好 `libk4a1.4_1.4.1_amd64.deb` `libk4a1.4-dev_1.4.1_amd64.deb` `k4a-tools_1.4.1_amd64.deb`之后，放入项目下同一文件夹，依次解压即可。

* 测试一下，输入 `k4aviewer` 即可打开摄像头。


#### 问题与解决方法

* 问题：安装`k4a-tools_1.4.1_amd64.deb`失败。
* 解决方法：注意各个包的安装顺序。解压k4a-tools之前需要先 `apt install libsoundio1`

### Openpose

安装Openpose以及相关依赖。

* 安装CUDA：https://blog.csdn.net/my__blog/article/details/125720601 此处下载的是CUDA11.8

* 安装cudnn：

  下载deb： https://developer.nvidia.com/rdp/cudnn-download

  安装：

  ```bash
  sudo dpkg -i cudnn-local-repo-ubuntu1804-8.9.4.25_1.0-1_amd64.deb 
  sudo apt-get update
  cd /var/cudnn-local-repo-ubuntu1804-8.9.4.25/
  sudo dpkg -i libcudnn8_8.9.4.25-1+cuda11.8_amd64.deb
  sudo dpkg -i libcudnn8-dev_8.9.4.25-1+cuda11.8_amd64.deb 
  sudo dpkg -i libcudnn8-samples_8.9.4.25-1+cuda11.8_amd64.deb 
  ```

  测试安装是否成功(创建一个空闲文件夹并进入该文件夹，执行下述操作)：

  ```bash
  cp -r /usr/src/cudnn_samples_v8/ ./
  cd cudnn_samples_v8/mnistCUDNN/
  sudo make clean
  sudo make
  ```


* 加入3d解释器的模型编译：

  首先需要根据 [官网](http://ceres-solver.org/installation.html#linux) 安装Ceres的必要依赖，之后根据参考[网址](https://blog.csdn.net/qq_41586768/article/details/107541917)安装1.14版本的Ceres。

  完成上述工作后，重新打开cmake-gui，勾选：

  - WITH_3D_RENDERER
  - WITH_CERES
  - WITH_EGIEN: AUTOBUILD

  重新进行设置与编译，出现的后续问题可以参考之前日志（23年2月19日）的记录。

#### 问题与解决方法

* 问题1：编译代码时报错

  ```
  ERROR:
  test.c:1:10: fatal error: FreeImage.h: No such file or directory
   #include "FreeImage.h"
  ```

* 解决方法：安装缺少的依赖：https://lequ7.com/guan-yu-ubuntu2004ubuntu2004-xian-ka-qu-dong-cudacudnn-guan-wang-an-zhuang-jiao-cheng.html 
  `sudo apt-get install g++ freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libglu1-mesa libglu1-mesa-dev`
  `sudo apt-get install libfreeimage3 libfreeimage-dev`

* 问题2：完成代码编译后，运行demo文件出现有关**CUDNN**的报错。


* 解决方法：在新的实验主机上，由于显卡型号改变，为RTX 3080显卡。其所需的最低CUDA版本为`11.x` 。于是在该主机上使用的版本信息为：

  CUDA: 11.7
  Cudnn: 8.9.4

  经过查阅资料，在cmake-gui设置时，取消勾选`USE_CUDNN` ，重新编译即可。这会带来显卡内存占用增加的问题，可以通过减小视频分辨率来解决，openpose原文如下：

```
The cuDNN library is not mandatory, but required for full keypoint detection accuracy. In case your graphics card is not compatible with cuDNN, you can disable it by unchecking USE_CUDNN in CMake.

Then, you would have to reduce the --net_resolution flag to fit the model into the GPU memory. You can try values like 640x320, 320x240, 320x160, or 160x80 to see your GPU memory capabilities. After finding the maximum approximate resolution that your GPU can handle without throwing an out-of-memory error, adjust the net_resolution ratio to your image or video to be processed (see the --net_resolution explanation from doc/advanced/demo_advanced.md), or use -1 (e.g., --net_resolution -1x320).
```

* 问题3：运行demo但是没有任何骨骼点

* 解决方法：可能的原因是model没有下载成功。可以通过检查openpose文件下models文件的大小来验证，如果有完整的模型，该文件夹大小应该为`734M`左右。

  如果openpose提供的模型下载地址不能访问，可以访问该模型下载链接：https://www.kaggle.com/datasets/changethetuneman/openpose-model/ 之后根据models文件中模型的名称，将空壳模型替换为下载到的完整模型即可。



## 2023/10/10

### Openpose

成功将图片转换为opencv matrix（参考 [How to convert k4a_image_t to opencv matrix? (Azure Kinect Sensor SDK) - Stack Overflow](https://stackoverflow.com/questions/57222190/how-to-convert-k4a-image-t-to-opencv-matrix-azure-kinect-sensor-sdk)），并完成了对kinectWrapper的编写。



## 2023/10/11

### Kinect

编译Kinect SDK源码，并探究在openpose项目中引用Kinect的k4a库。

[参考教程](https://github.com/microsoft/Azure-Kinect-Sensor-SDK/blob/develop/docs/building.md)

首先**下载源码**到文件夹中：`git clone https://github.com/microsoft/Azure-Kinect-Sensor-SDK.git`

在编译之前需要**准备好依赖**，在 *Azure-Kinect-Sensor-SDK/scripts/docker* 中给出了三种安装依赖的方式：Dockerfile、setup-ubuntu.sh以及依照sources.list手动安装。这里采用第二种方法，参考[Ubuntu18.04+Azure Kinect DK配置全过程（SDK源码+ROS）_azure kinect dk + ros18.04-CSDN博客](https://blog.csdn.net/qq_27399933/article/details/107356117?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-107356117-blog-124025953.235^v38^pc_relevant_sort_base3&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-107356117-blog-124025953.235^v38^pc_relevant_sort_base3&utm_relevant_index=1)

```bash
sudo chmod +x setup-ubuntu.sh
./setup-ubuntu.sh
```

然后就是**编译**了！编译过程中会自动下载一些东西，其中libyuv包无法下载，需要修改下载源：

在根目录（Azure-Kinect-Sensor-SDK）中`ls -a` 查看所有文件，找到被隐藏的.gitmodules，然后将libyuv的下载地址改为 `https://github.com/lemenkov/libyuv.git`

开始编译：

 ```bash
mkdir build
cd build
cmake .. -GNinja -DCMAKE_BUILD_TYPE=Debug
ninja
 ```

最后将SDK中的动态链接库等相关文件安装到系统目录中供其他项目使用：

`sudo ninja install`

**记住头文件和链接库的位置**： `/usr/include/k4a` 和 `/usr/local/lib`

* 用vscode编写自己的kinect程序

  * 在项目文件夹中运行 `code .` 打开vscode， `.` 表示以当前文件夹作为vscode项目目录。

  * 创建cpp文件，开始写代码！

  * 在cpp文件开头引用k4a相关库，如 `#include<k4a/k4a.h>`

  * 点击Terminal -> Configure Default Build Task创建tasks.json，这是后续编译的关键。一般选择C/C++ : g++ build active file

  * **在tasks.json的args参数中，添加：**

    ```
    "-L/usr/local/lib",
    "-lk4a"
    ```

    -L指定了链接库所在的文件夹， 而-l指定了具体用到的链接库。

  * 点击View -> Command Palette -> C/C++: Edit Configurations (UI) **创建c_cpp_properties.json，在includePath参数中添加：**

    ```
    "/usr/include/k4a"
    ```

  * 回到cpp文件，点击Terminal -> Run Build Task（或快捷键ctrl+shift+B）即可在同一文件夹下构建可执行文件。



## 2023/10/13

### Openpose

修改Openpose源码的CMakeList文件，使其编译时能链接到k4a库。

- 增加cmake-gui编译选项，并设置编译define

  ```cmake
  option(WITH_KINECT_CAMERA "Add KINECT camera code (requires Azure Kinect SDK already installed)." OFF)
  
  if (WITH_KINECT_CAMERA)
    # OpenPose flags
    add_definitions(-DUSE_KINECT_CAMERA)
  endif (WITH_KINECT_CAMERA)
  ```

- 查找 K4A 库

  ```cmake
  if (WITH_AZURE_KINECT)
    # Azure Kinect SDK
    find_package(k4a REQUIRED)
    if (NOT k4a_FOUND)
      message(FATAL_ERROR "Azure Kinect SDK not found. Either turn off the `WITH_AZURE_KINECT` option or specify the path to
        the Azure Kinect SDK includes and libs.")
    endif (NOT k4a_FOUND)
  endif (WITH_AZURE_KINECT)
  ```

- 将头文件加入项目

  ```cmake
  if (WITH_AZURE_KINECT)
      include_directories(SYSTEM ${K4A_INCLUDE_DIRS})
  endif (WITH_AZURE_KINECT)
  ```

- 在链接阶段将 k4a 库链接到 OpenPose 项目中

  ```cmake
  if (WITH_AZURE_KINECT)
      set(OpenPose_3rdparty_libraries ${OpenPose_3rdparty_libraries} ${K4A_LIB})
  endif (WITH_AZURE_KINECT)
  ```

#### 问题与解决方法

* 问题1：报错

  ```bash
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_capture_get_color_image'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_start_cameras'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_get_device_timestamp_usec'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_get_width_pixels'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_close'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_get_serialnum'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_open'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_reference'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_get_installed_count'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_release'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_capture_release'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_get_capture'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_set_color_control'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_stop_cameras'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_device_get_sync_jack'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_get_height_pixels'
  ../../src/openpose/libopenpose.so.1.7.0: undefined reference to `k4a_image_get_buffer'
  collect2: error: ld returned 1 exit status
  examples/tutorial_api_cpp/CMakeFiles/02_whole_body_from_image_default.bin.dir/build.make:175: recipe for target 'examples/tutorial_api_cpp/02_whole_body_from_image_default.bin' failed
  make[2]: *** [examples/tutorial_api_cpp/02_whole_body_from_image_default.bin] Error 1
  CMakeFiles/Makefile2:1254: recipe for target 'examples/tutorial_api_cpp/CMakeFiles/02_whole_body_from_image_default.bin.dir/all' failed
  make[1]: *** [examples/tutorial_api_cpp/CMakeFiles/02_whole_body
  ```


* 解决方法：`-lk4a` 告诉链接器使用名为 `k4a` 的库的标志，缺少这个标志可能导致链接错误。

  ```cmake
  if (WITH_AZURE_KINECT)
      set(OpenPose_3rdparty_libraries ${OpenPose_3rdparty_libraries} ${K4A_LIB} -lk4a)
  endif (WITH_AZURE_KINECT)
  ```


* 问题2：在代码执行期间产生如下有关USB的报错：

  ```bash
  ibusb_claim_interface(usbcmd->libusb, usbcmd->interface) returned LIBUSB_ERROR_BUSY in usb_cmd_create
  ```


* 解决方法：问题原因为在代码中在没有调用close函数的情况下，多次调用open函数：

  ```c++
  k4a::device::open(i);
  
  k4a::device::close();
  ```

  在一轮完整wrapper过程中，open函数只能被调用一次，之后如需要使用device_handle，使用引用传递即可。

* 问题3：`k4a::device`类中没有拷贝构造函数，其代码呈现如下：

  ```c++
  device(const device&) = delete
  ```


* 解决方法：这是一个 C++ 中的特殊声明，用于删除（`= delete`）拷贝构造函数。这种声明告诉编译器不允许使用拷贝构造函数创建该类的对象的副本。

  这样的设计通常出现在需要精确地控制对象的拷贝行为的情况下。例如，如果一个类管理了资源（比如内存或文件句柄），通过禁用拷贝构造函数可以防止意外的资源共享或释放。在现代 C++ 中，通常推荐使用移动语义来代替拷贝，因为移动操作更高效且更适合具有资源管理职责的类。

### Kinect

学习相机同步：[同步多个 Azure Kinect DK 设备 | Microsoft Learn](https://learn.microsoft.com/zh-CN/azure/Kinect-dk/multi-camera-sync)

开始进行[相机标定](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/advanced/calibration_module.md)：

创建intrinsic_images文件夹，然后分别为每个摄像头建立一个文件夹存放图片。

首先**拍摄图片**：`./build/examples/openpose/openpose.bin --num_gpu 0 --write_images {intrinsic_images_folder_path}`，大约150张。

然后**开始标定**，选用的标定板方格数量为10x7，单个方格边长100mm。

`./build/examples/calibration/calibration.bin --mode 1 --grid_square_size_mm 100.0 --grid_number_inner_corners "9x6" --calibration_image_dir {intrinsic_images_folder_path} --camera_parameter_folder models/cameraParameters/ --camera_serial_number kinect_0`

标定完成后的**输出结果**：

```
Intrinsics:
Re-projection error - cv::calibrateCamera vs. calcReprojectionErrors:	0.172223 vs. 0.172223
Intrinsics_K:
[601.9376454314838, 0, 636.0314657081125;
 0, 601.6451305260853, 366.2350131114671;
 0, 0, 1]
Intrinsics_distCoeff:
[32.34771773420155;
 43.43371397094068;
 0.001251353032398356;
 -0.0001609246650279393;
 102.9209972275133;
 32.3707038245662;
 41.79920174558191;
 100.9829996569434;
 0;
 0;
 0;
 0;
 0;
 0]
```

**打开相机**查看效果，注意要将参数文件名改为相机对应序列号：

`./build/examples/openpose/openpose.bin --num_gpu 0 --kinect_camera --kinect_camera_index 0 --frame_undistort`

#### 问题与解决方法

* 问题1：报错：could not open image
* 解决方法：在之前遇到过该问题。删除文件夹中最后一张照片即可。
* 问题2：报错：chessboard not found
* 解决方法：grid_number_inner_corners参数指的是标定板内部角点（即黑白小方块的交点）数量，而**非小方块数量**！正确的值应为9x6而非10x7。
* 问题3：相机标定质量差，标定完内参之后打开相机，画面四周出现一圈类似滤镜的效果，严重影响成像结果。
* 解决方法：回顾了相机标定的原理，重新拍摄照片，使得标定板以不同距离、角度出现在相机镜头的中央及各个边角。



## 2023/10/15

### Openpose

运行**Openpose同步代码**，实现Kinect摄像头的同步。

#### 问题与解决方法

* 问题：运行MultiDeviceCapture的start_camera函数，会找不到sub_device的handle。
* 解决方法：在执行MultiDeviceCapture的DeInit函数时，没有将附属设备向量进行clear操作，导致之后的Init操作在已经变成空指针的device handle后添加了新的device handle。这也导致sub_devices vector中元素个数比实际的附属设备个数多，从而在之后进行start_camera时访问到了空指针的device handle

### Kinect

解决同步问题后，完成多设备的**外参标定**。

首先**收集图片**：

`./build/examples/openpose/openpose.bin --kinect_camera --frame_undistort --write_images ./extrinsic_images`

这会同时为三台kinect拍摄图片，按照 `number_rendered.png number_rendered_1.png number_rendered_2.png`的形式存储，一组三张。

接着**开始标定**。标定外参时，以其中一个kinect的相机坐标系为世界坐标系原点，然后分别计算其余kinect相对其的旋转矩阵R和平移矩阵t。（理论：对于单目摄像机，没有必要标定其外参（或者说其拍摄的每一张图片都对应一个外参），因为完全可以让相机光心坐标系与世界坐标系重合；也因此单目摄像机无法完成三维的重建）

```bash
./build/examples/calibration/calibration.bin --mode 2 --grid_square_size_mm 100.0 --grid_number_inner_corners "9x6" --omit_distortion --calibration_image_dir ./extrinsic_images/ --cam0 0 --cam1 1 --camera_parameter_folder ./models/cameraParameters/kinect/
```

建议拍摄250组以上图片获得好的标定效果。

#### 问题与解决方法

* 问题：报错：

  ```bash
  vector::\_M\_range\_check: \_\_n(which is 1) >= this -> size() (which is 0)
  ```


* 解决方法：默认的相机内参文件路径为`models/cameraParameters/flir/`，因此要加上camera_parameter_folder的flag。



## 2023/10/22

### Kinect

重新标定了先前效果不佳的内参，并且完成最终的参数标定。

### Openpose

结合之前所有工作，运行Openpose的3D重建模块，顺利完成三维重建。



## 2023/10/26

完成项目收尾工作，安排结题报告等任务分配。

### 结题报告

- 项目研究内容 
- 项目研究方案 
- 项目完成情况 
- 项目特色与创新
- 项目研究取得的成果
- 项目成员贡献排序与工作备注
- 项目还存在哪些问题，有哪些建议。
- 项目研究心得

### 项目研究论文

- 引言
- 项目元素介绍
  - 三维重建[3D 人体姿态估计简述 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/400922771)
  - Openpose项目
  - 相机标定原理
  - Azure Kinect 

- 研究工作
  - 工作流程
  - 环境配置
  - 源码修改
  - 参数标定
- 应用场景与社会效益
- 总结

### 项目研究综述

（创新点、特色和应用及推广前景）

- 研究背景和方向
- 研究理论基础
- 实验过程
- 应用与推广前景
- 总结

### 个人总结

**每人一份**，可以放照片，内容包含承担的工作，发挥的作用，以及在能力培养和素质提高特别是在创新思维和创新实践方面的体验和收获。
